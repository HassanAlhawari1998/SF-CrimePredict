{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "| Links ausgerichtet | Mittig ausgerichtet | Rechts ausgerichtet |\n",
    "|:------------------ |:-------------------:| -------------------:|\n",
    "| Inhalt             | Inhalt              | Inhalt              |\n",
    "| Inhalt             | Inhalt              | Inhalt              |\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RF - Random Forest\n",
    "\n",
    "Random Forest is a powerful ensemble learning method that operates by constructing a multitude of decision trees during training. Each tree in the forest independently predicts the target variable and the final prediction is determined by averaging among these individual predictions. Random Forest is particularly adept at handling high-dimensional data and mitigating overfitting which we need in our case."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, log_loss, mean_squared_error\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, log_loss, mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Helper.Data import loadData\n",
    "from Helper.Perform_CrossVal import perform_cross_validation\n",
    "from Helper.Perform_GridSearch import perform_grid_search\n",
    "import pickle\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                 X          Y  DayOfWeek_Friday  DayOfWeek_Monday  \\\n0      -122.426995  37.800873               0.0               0.0   \n1      -122.438738  37.771541               0.0               0.0   \n2      -122.403252  37.713431               0.0               0.0   \n3      -122.423327  37.725138               0.0               0.0   \n4      -122.371274  37.727564               0.0               0.0   \n...            ...        ...               ...               ...   \n395397 -122.431046  37.783030               0.0               1.0   \n395398 -122.414073  37.751685               0.0               1.0   \n395399 -122.389769  37.730564               0.0               1.0   \n395400 -122.447364  37.731948               0.0               1.0   \n395401 -122.403390  37.780266               0.0               1.0   \n\n        DayOfWeek_Saturday  DayOfWeek_Sunday  DayOfWeek_Thursday  \\\n0                      0.0               0.0                 0.0   \n1                      0.0               0.0                 0.0   \n2                      0.0               0.0                 0.0   \n3                      0.0               0.0                 0.0   \n4                      0.0               0.0                 0.0   \n...                    ...               ...                 ...   \n395397                 0.0               0.0                 0.0   \n395398                 0.0               0.0                 0.0   \n395399                 0.0               0.0                 0.0   \n395400                 0.0               0.0                 0.0   \n395401                 0.0               0.0                 0.0   \n\n        DayOfWeek_Tuesday  DayOfWeek_Wednesday  PdDistrict_BAYVIEW  ...  \\\n0                     0.0                  1.0                 0.0  ...   \n1                     0.0                  1.0                 0.0  ...   \n2                     0.0                  1.0                 0.0  ...   \n3                     0.0                  1.0                 0.0  ...   \n4                     0.0                  1.0                 1.0  ...   \n...                   ...                  ...                 ...  ...   \n395397                0.0                  0.0                 0.0  ...   \n395398                0.0                  0.0                 0.0  ...   \n395399                0.0                  0.0                 1.0  ...   \n395400                0.0                  0.0                 0.0  ...   \n395401                0.0                  0.0                 0.0  ...   \n\n        Events_Clear  Events_Fog  Events_Fog-Rain  Events_Rain  \\\n0                1.0         0.0              0.0          0.0   \n1                1.0         0.0              0.0          0.0   \n2                1.0         0.0              0.0          0.0   \n3                1.0         0.0              0.0          0.0   \n4                1.0         0.0              0.0          0.0   \n...              ...         ...              ...          ...   \n395397           1.0         0.0              0.0          0.0   \n395398           1.0         0.0              0.0          0.0   \n395399           1.0         0.0              0.0          0.0   \n395400           1.0         0.0              0.0          0.0   \n395401           1.0         0.0              0.0          0.0   \n\n        Events_Rain-Thunderstorm  Events_Thunderstorm  season_Autumn  \\\n0                            0.0                  0.0            0.0   \n1                            0.0                  0.0            0.0   \n2                            0.0                  0.0            0.0   \n3                            0.0                  0.0            0.0   \n4                            0.0                  0.0            0.0   \n...                          ...                  ...            ...   \n395397                       0.0                  0.0            0.0   \n395398                       0.0                  0.0            0.0   \n395399                       0.0                  0.0            0.0   \n395400                       0.0                  0.0            0.0   \n395401                       0.0                  0.0            0.0   \n\n        season_Spring  season_Summer  season_Winter  \n0                 1.0            0.0            0.0  \n1                 1.0            0.0            0.0  \n2                 1.0            0.0            0.0  \n3                 1.0            0.0            0.0  \n4                 1.0            0.0            0.0  \n...               ...            ...            ...  \n395397            0.0            0.0            1.0  \n395398            0.0            0.0            1.0  \n395399            0.0            0.0            1.0  \n395400            0.0            0.0            1.0  \n395401            0.0            0.0            1.0  \n\n[395402 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X</th>\n      <th>Y</th>\n      <th>DayOfWeek_Friday</th>\n      <th>DayOfWeek_Monday</th>\n      <th>DayOfWeek_Saturday</th>\n      <th>DayOfWeek_Sunday</th>\n      <th>DayOfWeek_Thursday</th>\n      <th>DayOfWeek_Tuesday</th>\n      <th>DayOfWeek_Wednesday</th>\n      <th>PdDistrict_BAYVIEW</th>\n      <th>...</th>\n      <th>Events_Clear</th>\n      <th>Events_Fog</th>\n      <th>Events_Fog-Rain</th>\n      <th>Events_Rain</th>\n      <th>Events_Rain-Thunderstorm</th>\n      <th>Events_Thunderstorm</th>\n      <th>season_Autumn</th>\n      <th>season_Spring</th>\n      <th>season_Summer</th>\n      <th>season_Winter</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-122.426995</td>\n      <td>37.800873</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-122.438738</td>\n      <td>37.771541</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-122.403252</td>\n      <td>37.713431</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-122.423327</td>\n      <td>37.725138</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-122.371274</td>\n      <td>37.727564</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395397</th>\n      <td>-122.431046</td>\n      <td>37.783030</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>395398</th>\n      <td>-122.414073</td>\n      <td>37.751685</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>395399</th>\n      <td>-122.389769</td>\n      <td>37.730564</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>395400</th>\n      <td>-122.447364</td>\n      <td>37.731948</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>395401</th>\n      <td>-122.403390</td>\n      <td>37.780266</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>395402 rows × 31 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final, y, X_train, X_test, y_train, y_test, data, feature_columns, categorical_features,target_column, label_encoder = loadData()\n",
    "X_final"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In Random Forest for multi-class classification, categorical features may require numerical encoding, but the target variable can be provided as either strings or integers directly, without needing binary transformation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code initializes a Random Forest classifier named rf_clf, specifying two parameters:\n",
    "- n_estimators: The n_estimators parameter in Random Forest determines the number of decision trees in the ensemble. Increasing it can improve performance, but it also increases training and prediction times. Too many trees may lead to overfitting and diminishing returns. In this case, 100 trees are used, which is a common default choice balancing between model performance and computational efficiency.\n",
    "- random_state: ensures reproducibility of results by setting the random number generator seed for consistent model evaluation and comparison across different runs or environments."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 41.8136%\n",
      "Standard deviation accuracy: 1.9134%\n",
      "Average f1_macro: 30.6033%\n",
      "Standard deviation f1_macro: 1.7710%\n",
      "Average roc_auc_ovr: 64.2488%\n",
      "Standard deviation roc_auc_ovr: 0.5959%\n",
      "Difference in std between train and test accuracy: -1.7746%\n",
      "Difference in std between train and test f1_macro: -1.6224%\n",
      "Difference in std between train and test roc_auc_ovr: -0.5644%\n"
     ]
    }
   ],
   "source": [
    "# define scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'roc_auc_ovr': 'roc_auc_ovr'\n",
    "}\n",
    "\n",
    "# cross validation\n",
    "cv_results = cross_validate(rf_clf, X_final, y, cv=4, scoring=scoring, return_train_score=True)\n",
    "\n",
    "# average and std results\n",
    "for metric in scoring.keys():\n",
    "    print(f\"Average {metric}: {np.mean(cv_results[f'test_{metric}']) * 100:.4f}%\")\n",
    "    print(f\"Standard deviation {metric}: {np.std(cv_results[f'test_{metric}']) * 100:.4f}%\")\n",
    "\n",
    "# differences between train and test\n",
    "for metric in scoring.keys():\n",
    "    test_std = np.std(cv_results[f'test_{metric}'])\n",
    "    train_std = np.std(cv_results[f'train_{metric}'])\n",
    "    print(f\"Difference in std between train and test {metric}: {(train_std - test_std) * 100:.4f}%\")\n",
    "\n",
    "with open('rf_cross_val_result.pkl', 'wb') as f:\n",
    "    pickle.dump(cv_results, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preliminary Testing Crossvalidation Results\n",
    "Given the context of a multiclass classification scenario with five different outcomes, let's delve into interpreting our cross-validation results:\n",
    "- **Average Accuracy 41.82%**: In our initial testing, Random Forest demonstrated a low average accuracy of 41.8136% in a 5-fold cross-validation. Though better than random guessing, it still falls short. It appears to struggle with our multiclass problem too.\n",
    "- **Standard Deviation of Accuracy 1.91%**: The model's performance remains stable across various subsets of our data.\n",
    "- **Average Macro F1 Score 30.60%**: A score of 30.60% reflects a significant challenge, signaling that the model encounters difficulties with both precision and recall uniformly across all classes. This hints at potential issues in correctly recognizing all instances of a class or in distinguishing between classes without generating numerous incorrect predictions.\n",
    "- **Standard Deviation of Macro F1 Score 1.77%**: A standard deviation of about 2%, is evident in the precision and recall of the model across folds. It doesn't exceed excessive levels.\n",
    "\n",
    "- **Average ROC_AUC_OVR 64.25%**: A score of 64.25% indicates the model's proficiency in distinguishing between different categories. It's important to consider that this score might be even higher given the challenge of dealing with multiple classes.\n",
    "\n",
    "- **Differences in Standard Deviation Between Train and Test (Accuracy, F1 Macro, ROC_AUC_OVR)**: The model being more consistent on the test set than on the training set, possibly indicating underfitting and reduced accuracy in capturing data complexity.\n",
    "\n",
    "#### Preliminary Testing Crossvalidation Conclusion\n",
    "Overall our model displays stable performance across folds but faces challenges in achieving high accuracy, particularly in precision and recall, resulting in a low F1 score. The ROC_AUC_OVR score indicates an acceptable level, however, there is still substantial potential for overall enhancement."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5288\n",
      "F1-score: 0.5156\n",
      "ROC-AUC Score (Binary): 0.4813\n",
      "Log Loss: 2.5616\n"
     ]
    }
   ],
   "source": [
    "# Training the classifier\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Predicting the probabilities for the test set\n",
    "y_pred_proba = rf_clf.predict_proba(X_test)\n",
    "\n",
    "# Calculation of various metrics\n",
    "# We use the “weighted” parameter because this takes imbalances into account\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Random Forest does not provide probability estimates directly like XGBoost\n",
    "# For ROC-AUC score, we can only calculate it for binary or multiclass classification with one-vs-one or one-vs-rest strategy.\n",
    "# Here, we'll calculate ROC-AUC score for binary classification since RandomForestClassifier does not output probabilities for multiclass directly.\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_test)\n",
    "y_test_binarized = lb.transform(y_test)\n",
    "y_pred_binarized = lb.transform(y_pred)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test_binarized[:, 0], y_pred_proba[:, 1])  # Assuming binary classification\n",
    "logloss = log_loss(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC Score (Binary): {roc_auc:.4f}\")\n",
    "print(f\"Log Loss: {logloss:.4f}\")\n",
    "\n",
    "with open('random_forest_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_clf, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preliminary Testing Prediction Results\n",
    "- **Accuracy 52.88%**: An accuracy of 52.88% indicates that the model correctly predicts the outcome more than half of the time. While still showing room for improvement, this suggests the model is performing significantly better than expected in comparison to cross-validation results.\n",
    "- **F1-score 51.563%**: The F1-score is 51.563, indicating room for improvement in balancing precision and recall, particularly in multiclass classification contexts where achieving high precision and recall is challenging.\n",
    "- **ROC-AUC OVO Score 48.13%**: This score falls below 50%, suggesting challenges in distinguishing between the various classes.\n",
    "\n",
    "\n",
    "#### Preliminary Testing Prediction Conclusion\n",
    "The results are acceptable for preliminary testing, however, there is a clear need for improvement, particularly in enhancing the ROC for distinguishing different classes and other relevant scores above 50%."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# extract feature importance\n",
    "importance = rf_clf.feature_importances_\n",
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "# plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(importance)), importance)\n",
    "plt.xticks(range(len(importance)), feature_names, rotation=90)\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "# initialise RFECV\n",
    "cv_strategy = StratifiedKFold(n_splits=5)\n",
    "rfecv = RFECV(estimator=rf_clf, step=1, cv=cv_strategy, scoring='accuracy')\n",
    "\n",
    "# RFECV fit\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "# print optimal number of features\n",
    "print(\"Optimal number of features: %d\" % rfecv.n_features_)\n",
    "\n",
    "# Extracting the feature names based on RFECV support\n",
    "#selected_features = X_train.columns[rfecv.support_]\n",
    "\n",
    "# Output of the selected feature names and their rankings\n",
    "print(\"Selected features and their rankings:\")\n",
    "for rank, feature in zip(rfecv.ranking_, X_train.columns):\n",
    "    print(f\"{feature}: Rank {rank}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross Validation Score (Accuracy)\")\n",
    "plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), rfecv.cv_results_['mean_test_score'])\n",
    "plt.title('RFECV - Performance of the model')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion Matrix\n",
    "y_test_names = label_encoder.inverse_transform(y_test)\n",
    "cm = confusion_matrix(y_test_names, label_encoder.inverse_transform(y_pred)) # Annahme, dass y_pred die Vorhersagen sind\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_classes = y_test_binarized.shape[1]\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "colors = cycle(['blue', 'red', 'green', 'orange', 'black'])\n",
    "\n",
    "# plot ROC\n",
    "plt.figure(figsize=(7, 5))\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    # Ersetzen von `i` durch `label_encoder.classes_[i]` für die Klassennamen\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(label_encoder.classes_[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# GridSearchCV-initialization\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=param_grid, scoring='accuracy', cv=4, n_jobs=-1)\n",
    "\n",
    "# search for best params\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# scores\n",
    "print(f\"Best  : {grid_search.best_params_}\")\n",
    "print(f\"Best Accuracy: {grid_search.best_score_ * 100:.2f}%\")\n",
    "with open('rfgrid_search.pkl', 'wb') as f:\n",
    "    pickle.dump(grid_search, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_rf_clf = RandomForestClassifier(**best_params, random_state=42)\n",
    "\n",
    "best_rf_clf.fit(X_train, y_train)\n",
    "y_pred = best_rf_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, F1-score, and ROC-AUC\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, best_rf_clf.predict_proba(X_test), multi_class='ovr', average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Accuracy on test data: {accuracy:.4f}\")\n",
    "print(f\"F1-score on test data: {f1:.4f}\")\n",
    "print(f\"ROC-AUC on test data: {roc_auc:.4f}\")\n",
    "\n",
    "with open('random_forest_model2.pkl', 'wb') as f:\n",
    "    pickle.dump(best_rf_clf, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
